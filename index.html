<!DOCTYPE html>
<html lang="en">
  
  <head>
    <meta charset="UTF-8" />
    <title>De-AntiFake</title>
    <meta name="viewport" content="width=device-width, initial-scale=1" />
    <meta name="theme-color" content="#157878" />
    <link rel="stylesheet" href="css/normalize.css" />
    <link href="https://fonts.googleapis.com/css?family=Open+Sans:400,700" rel="stylesheet" type="text/css" />
    <link rel="stylesheet" href="css/cayman.css" />
    <link rel="stylesheet" href="css/custom.css" />
    <link rel="icon" href="#">
    <script src="https://polyfill.io/v3/polyfill.min.js?features=es6"></script>
    <script id="MathJax-script" async src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
  </head>

  <body>
    <section class="page-header">
      <h1 class="project-name">De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks</h1>
      <h2 class="project-tagline">by Wei Fan, Kejiang Chen, Chang Liu, Weiming Zhang, and Nenghai Yu</h2>
      <a href="index.html" class="btn">Home</a>
      <a href="https://github.com/cyberrrange/de-antifake" class="btn">Code</a>
      <a href="samples.html" class="btn">Audio Samples</a>
      <a href="subjective.html" class="btn">Subjective Test Samples</a>
    </section>

<section class="main-content">
      
  <div id="home">
    <h2>Introduction</h2>
    This is the homepage of the paper "De-AntiFake: Rethinking the Protective Perturbations Against Voice Cloning Attacks". The paper's open-source code can be accessed <a href="https://github.com/cyberrrange/de-antifake">here</a>.


    <h2>Abstract</h2>

    <p>
      &nbsp;&nbsp;The rapid advancement of speech generation models has heightened privacy and security concerns related to voice cloning (VC). Recent studies have investigated disrupting unauthorized voice cloning by introducing adversarial perturbations. However, determined attackers can mitigate these protective perturbations and successfully execute VC.
      <br>&nbsp;&nbsp;In this study, we conduct the first systematic evaluation of these protective perturbations against VC under realistic threat models that include perturbation purification. Our findings reveal that while existing purification methods can neutralize a considerable portion of the protective perturbations, they still lead to distortions in the feature space of VC models, which degrades the performance of VC.
      <br>&nbsp;&nbsp;From this perspective, we propose a novel two-stage purification method: (1) Purify the perturbed speech; (2) Refine it using phoneme guidance to align it with the clean speech distribution. Experimental results demonstrate that our method outperforms state-of-the-art purification methods in disrupting VC defenses. Our study reveals the limitations of adversarial perturbation-based VC defenses and underscores the urgent need for more robust solutions to mitigate the security and privacy risks posed by VC.
    </p>


    

  </div>

</section>

  </body>
</html>
